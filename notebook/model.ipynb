{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import r_regression, SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import shap\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from bisect import bisect\n",
    "\n",
    "import re\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(r\"C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\portfolio/\\VehicleLoanDefault/\\data\")\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
    "info_df = pd.read_csv(os.path.join(data_path, 'data_dictionary.csv'))\n",
    "\n",
    "# getting some numerical features' names from beurau data\n",
    "bearue_num_feats_list = list(info_df.iloc[22:, :]['Variable Name'].values)\n",
    "bearue_num_feats_list.remove('AVERAGE.ACCT.AGE')\n",
    "bearue_num_feats_list.remove('CREDIT.HISTORY.LENGTH')\n",
    "bearue_num_feats_list.extend(['avg_loan_tenure', 'hist_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No Bureau History Available': 1,\n",
       " 'I-Medium Risk': 2,\n",
       " 'L-Very High Risk': 3,\n",
       " 'A-Very Low Risk': 4,\n",
       " 'Not Scored: Not Enough Info available on the customer': 5,\n",
       " 'D-Very Low Risk': 6,\n",
       " 'M-Very High Risk': 7,\n",
       " 'B-Very Low Risk': 8,\n",
       " 'C-Very Low Risk': 9,\n",
       " 'E-Low Risk': 10,\n",
       " 'H-Medium Risk': 11,\n",
       " 'F-Low Risk': 12,\n",
       " 'K-High Risk': 13,\n",
       " 'Not Scored: No Activity seen on the customer (Inactive)': 14,\n",
       " 'Not Scored: Sufficient History Not Available': 15,\n",
       " 'Not Scored: No Updates available in last 36 months': 16,\n",
       " 'G-Low Risk': 17,\n",
       " 'J-High Risk': 18,\n",
       " 'Not Scored: Only a Guarantor': 19,\n",
       " 'Not Scored: More than 50 active Accounts found': 20}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs = [(1,20,\"Cap\"), (2,18,\"Aqu\"), (3,20,\"Pis\"), (4,20,\"Ari\"),\n",
    "         (5,21,\"Tau\"), (6,21,\"Gem\"), (7,22,\"Can\"), (8,23,\"Leo\"),\n",
    "         (9,23,\"Vir\"), (10,23,\"Lib\"), (11,22,\"Sco\"), (12,22,\"Sag\"),\n",
    "         (12,31,\"Cap\")]\n",
    "\n",
    "def zodiac_sign(m,d):\n",
    "    return signs[bisect(signs,(m,d))][2]\n",
    "\n",
    "train_df['DisbursalDate'] = pd.to_datetime(train_df['DisbursalDate'])#, format=\"%Y-%m-%d\")\n",
    "train_df['Date.of.Birth'] = pd.to_datetime(train_df['Date.of.Birth'])#, format=\"%Y-%m-%d\")\n",
    "train_df['age'] = round((train_df['DisbursalDate'] - train_df['Date.of.Birth']).dt.days / 365, 1)\n",
    "\n",
    "train_df['disb_month'] = train_df['DisbursalDate'].dt.month\n",
    "train_df['zodiac_sign'] = train_df['Date.of.Birth'].apply(lambda x: zodiac_sign(x.month, x.day))\n",
    "\n",
    "def convert2numbers(x):\n",
    "    derived_numbers = re.findall(r'(\\d+)yrs (\\d+)mon', x)\n",
    "    return round(int(derived_numbers[0][0]) + int(derived_numbers[0][1]) / 12, 2)\n",
    "\n",
    "train_df['avg_loan_tenure'] = train_df['AVERAGE.ACCT.AGE'].apply(convert2numbers)\n",
    "train_df['hist_length'] = train_df['CREDIT.HISTORY.LENGTH'].apply(convert2numbers)\n",
    "\n",
    "score_desc_list = list(train_df['PERFORM_CNS.SCORE.DESCRIPTION'].unique())\n",
    "score_desc_map_dict = {score_desc_list[i]: i+1 for i in range(len(score_desc_list))}\n",
    "\n",
    "train_df['score_desc'] = train_df['PERFORM_CNS.SCORE.DESCRIPTION'].map(score_desc_map_dict)\n",
    "\n",
    "train_df['Employment.Type'].fillna('Unknown', inplace=True)\n",
    "\n",
    "employment_type_list = list(train_df['Employment.Type'].unique())\n",
    "employment_type_map_dict = {employment_type_list[i]: i+1 for i in range(len(employment_type_list))}\n",
    "\n",
    "train_df['Employment.Type'] = train_df['Employment.Type'].map(employment_type_map_dict)\n",
    "\n",
    "zodiac_list = list(train_df['zodiac_sign'].unique())\n",
    "zodiac_map_dict = {zodiac_list[i]: i+1 for i in range(len(zodiac_list))}\n",
    "\n",
    "train_df['zodiac_sign'] = train_df['zodiac_sign'].map(zodiac_map_dict)\n",
    "\n",
    "for i in range(len(bearue_num_feats_list)):\n",
    "    for j in range(len(bearue_num_feats_list)):\n",
    "        if i != j:\n",
    "            train_df[f\"{bearue_num_feats_list[i]}_ratio{j+1}\"] = train_df[bearue_num_feats_list[i]] / \\\n",
    "                (train_df[bearue_num_feats_list[j]] + 1000)\n",
    "            \n",
    "created_ratio_list = [col for col in train_df.columns if '_ratio' in col]\n",
    "\n",
    "train_df.drop(\n",
    "    columns=[\n",
    "        'DisbursalDate', 'Date.of.Birth', \n",
    "        'AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH',\n",
    "        'PERFORM_CNS.SCORE.DESCRIPTION', 'MobileNo_Avl_Flag'\n",
    "    ], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "score_desc_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Salaried': 1, 'Self employed': 2, 'Unknown': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employment_type_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cap': 1,\n",
       " 'Leo': 2,\n",
       " 'Vir': 3,\n",
       " 'Ari': 4,\n",
       " 'Sco': 5,\n",
       " 'Can': 6,\n",
       " 'Aqu': 7,\n",
       " 'Tau': 8,\n",
       " 'Pis': 9,\n",
       " 'Lib': 10,\n",
       " 'Gem': 11,\n",
       " 'Sag': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zodiac_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['DisbursalDate'] = pd.to_datetime(test_df['DisbursalDate'])#, format=\"%d-%m-%Y\")\n",
    "test_df['Date.of.Birth'] = pd.to_datetime(test_df['Date.of.Birth'])#, format=\"%d-%m-%Y\")\n",
    "test_df['age'] = round((test_df['DisbursalDate'] - test_df['Date.of.Birth']).dt.days / 365, 1)\n",
    "\n",
    "test_df['disb_month'] = test_df['DisbursalDate'].dt.month\n",
    "test_df['zodiac_sign'] = test_df['Date.of.Birth'].apply(lambda x: zodiac_sign(x.month, x.day))\n",
    "\n",
    "test_df['avg_loan_tenure'] = test_df['AVERAGE.ACCT.AGE'].apply(convert2numbers)\n",
    "test_df['hist_length'] = test_df['CREDIT.HISTORY.LENGTH'].apply(convert2numbers)\n",
    "\n",
    "test_df['score_desc'] = test_df['PERFORM_CNS.SCORE.DESCRIPTION'].map(score_desc_map_dict)\n",
    "\n",
    "test_df['Employment.Type'].fillna('Unknown', inplace=True)\n",
    "\n",
    "test_df['Employment.Type'] = test_df['Employment.Type'].map(employment_type_map_dict)\n",
    "\n",
    "test_df['zodiac_sign'] = test_df['zodiac_sign'].map(zodiac_map_dict)\n",
    "\n",
    "for i in range(len(bearue_num_feats_list)):\n",
    "    for j in range(len(bearue_num_feats_list)):\n",
    "        if i != j:\n",
    "            test_df[f\"{bearue_num_feats_list[i]}_ratio{j+1}\"] = test_df[bearue_num_feats_list[i]] / \\\n",
    "                (test_df[bearue_num_feats_list[j]] + 1000)\n",
    "\n",
    "test_df.drop(\n",
    "    columns=[\n",
    "        'DisbursalDate', 'Date.of.Birth', \n",
    "        'AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH',\n",
    "        'PERFORM_CNS.SCORE.DESCRIPTION', 'MobileNo_Avl_Flag'\n",
    "    ], \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "skfold_list = []\n",
    "for train_idxs, valid_idxs in skfold.split(train_df, y=train_df['loan_default']):\n",
    "    skfold_list.append((train_idxs, valid_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection and model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iqr(x):\n",
    "     iqr = np.quantile(x, 0.75) - np.quantile(x, 0.25)\n",
    "     return iqr\n",
    "\n",
    "def get_q25(x):\n",
    "     return np.quantile(x, 0.25)\n",
    "\n",
    "def get_q75(x):\n",
    "     return np.quantile(x, 0.75) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSelector():\n",
    "\n",
    "    def __init__(self, X, y, num_feats, ordinal_feats, nominal_feats, model, is_target_cat=True, select_n_feats=15):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.num_feats = num_feats\n",
    "        self.ordinal_feats = ordinal_feats\n",
    "        self.nominal_feats = nominal_feats\n",
    "        self.model = model\n",
    "        self.is_target_cat = is_target_cat\n",
    "        self.select_n_feats = select_n_feats\n",
    "\n",
    "    def calculate_vif(self, X):\n",
    "    \n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"features\"] = X.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "        return vif\n",
    "\n",
    "    def select_feats_via_vif(self):\n",
    "\n",
    "        num_features = self.num_feats.copy()\n",
    "\n",
    "        vif_df = self.calculate_vif(self.X[num_features])\n",
    "\n",
    "        while vif_df[vif_df['VIF']>=10].shape[0] != 0:\n",
    "            vif_df.sort_values('VIF', ascending=False, inplace=True)\n",
    "            vif_df.reset_index(drop=True, inplace=True)\n",
    "            # print(vif_df)\n",
    "            elimination_candidate = vif_df.iloc[0]['features']\n",
    "            # print(elimination_candidate)\n",
    "            num_features = [i for i in num_features if i!=elimination_candidate]\n",
    "            new_X = self.X[num_features]\n",
    "            vif_df = self.calculate_vif(new_X)\n",
    "\n",
    "        return list(vif_df['features'].values)\n",
    "    \n",
    "    def get_spearmanr(self, X, y):\n",
    "        # return np.array([stats.spearmanr(X.values[:, f], y.values).correlation for f in range(X.shape[1])])\n",
    "        spearman_values = [stats.spearmanr(X.values[:, f], y.values).correlation for f in range(X.shape[1])]\n",
    "        temp_sp_df = pd.DataFrame({'spearman': spearman_values, 'feats': list(X.columns)})\n",
    "        temp_sp_df['abs_spearman'] = np.abs(temp_sp_df['spearman'])\n",
    "        temp_sp_df.sort_values('abs_spearman', ascending=False, inplace=True)\n",
    "        temp_sp_df.reset_index(drop=True, inplace=True)\n",
    "        return temp_sp_df.iloc[:15]['feats'].to_list()\n",
    "    \n",
    "    def get_kendalltau(self, X, y):\n",
    "        # return [stats.kendalltau(X.values[:, f], y.values).correlation for f in range(X.shape[1])]\n",
    "        kendall_values = [stats.spearmanr(X.values[:, f], y.values).correlation for f in range(X.shape[1])]\n",
    "        temp_ken_df = pd.DataFrame({'kendall': kendall_values, 'feats': list(X.columns)})\n",
    "        temp_ken_df['abs_kendall'] = np.abs(temp_ken_df['kendall'])\n",
    "        temp_ken_df.sort_values('abs_kendall', ascending=False, inplace=True)\n",
    "        temp_ken_df.reset_index(drop=True, inplace=True)\n",
    "        return temp_ken_df.iloc[:15]['feats'].to_list()\n",
    "    \n",
    "    def get_pointbiserialr(self, X, y):\n",
    "        return [stats.pointbiserialr(X.values[:, f], y.values).correlation for f in range(X.shape[1])]\n",
    "    \n",
    "    def get_boruto_feats(self):\n",
    "        feat_selector = BorutaPy(self.model, n_estimators='auto', verbose=2, random_state=1)\n",
    "        feat_selector.fit(np.array(self.X), np.array(self.y))\n",
    "        boruta_selected_features = list(self.X.iloc[:, feat_selector.support_].columns)\n",
    "        return boruta_selected_features\n",
    "    \n",
    "    def get_kbest(self, X, feats_list, metric):\n",
    "        selector = SelectKBest(metric, k=self.select_n_feats)\n",
    "        selector.fit_transform(X[feats_list], self.y)\n",
    "        selected_feats_idxs_list = list(selector.get_support(indices=True))\n",
    "        column_names = [feats_list[i] for i in selected_feats_idxs_list]\n",
    "        return column_names\n",
    "    \n",
    "    def get_rfe_feats(self):\n",
    "        model_rfe = RFE(self.model, n_features_to_select=self.select_n_feats)\n",
    "        model_rfe.fit(self.X, self.y)\n",
    "        model_rfe_feats = list(self.X.iloc[:, list(model_rfe.support_)].columns)\n",
    "        return model_rfe_feats\n",
    "    \n",
    "    def get_votes(self):\n",
    "\n",
    "        if self.num_feats is not None:\n",
    "\n",
    "            if self.is_target_cat:\n",
    "\n",
    "                # self.num_kendalltau_feats = self.get_kendalltau(self.X[self.num_feats], self.y)\n",
    "                self.num_f_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=f_classif)\n",
    "                self.num_mi_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=mutual_info_classif)\n",
    "\n",
    "                self.selected_num_feats = []\n",
    "                # self.selected_num_feats.extend(self.num_kendalltau_feats)\n",
    "                self.selected_num_feats.extend(self.num_f_feats)\n",
    "                self.selected_num_feats.extend(self.num_mi_feats)\n",
    "\n",
    "            else:\n",
    "\n",
    "                self.vif_feats = self.select_feats_via_vif()\n",
    "\n",
    "                self.pearson_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=r_regression, k=self.select_n_feats)\n",
    "                # self.num_spearmanr_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=stats.spearmanr, k=self.select_n_feats)\n",
    "                # self.num_kendalltau_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=stats.kendalltau, k=self.select_n_feats)\n",
    "                self.num_spearmanr_feats = self.get_spearmanr(self.X[self.num_feats], self.y)\n",
    "                self.num_kendalltau_feats = self.get_kendalltau(self.X[self.num_feats], self.y)\n",
    "                # self.num_spearmanr_feats = SelectKBest(self.get_spearmanr, k=self.select_n_feats).fit_transform(self.X[self.num_feats], self.y)\n",
    "                # self.num_kendalltau_feats = SelectKBest(self.get_kendalltau, k=self.select_n_feats).fit_transform(self.X[self.num_feats], self.y)\n",
    "\n",
    "                self.selected_num_feats = []\n",
    "                self.selected_num_feats.extend(self.pearson_feats)\n",
    "                self.selected_num_feats.extend(self.num_spearmanr_feats)\n",
    "                self.selected_num_feats.extend(self.num_kendalltau_feats)\n",
    "                # self.selected_num_feats = list(set(self.selected_num_feats))\n",
    "\n",
    "        if self.ordinal_feats is not None:\n",
    "\n",
    "            if self.is_target_cat:\n",
    "\n",
    "                self.ordinal_mi_feats = self.get_kbest(X=self.X, feats_list=self.ordinal_feats, metric=mutual_info_classif)\n",
    "                self.ordinal_chi2_feats = self.get_kbest(X=self.X, feats_list=self.ordinal_feats, metric=chi2)\n",
    "\n",
    "                self.selected_ordinal_feats = []\n",
    "                self.selected_ordinal_feats.extend(self.ordinal_mi_feats)\n",
    "                self.selected_ordinal_feats.extend(self.ordinal_chi2_feats)\n",
    "\n",
    "            else:\n",
    "\n",
    "                self.ordinal_spearmanr_feats = self.get_spearmanr(self.X[self.ordinal_feats], self.y)\n",
    "                self.ordinal_kendalltau_feats = self.get_kendalltau(self.X[self.ordinal_feats], self.y)\n",
    "\n",
    "                # self.ordinal_spearmanr_feats = self.get_kbest(X=self.X, feats_list=self.ordinal_feats, metric=stats.spearmanr, k=self.select_n_feats)\n",
    "                # self.ordinal_kendalltau_feats = self.get_kbest(X=self.X, feats_list=self.ordinal_feats, metric=stats.kendalltau, k=self.select_n_feats)\n",
    "\n",
    "                # self.ordinal_spearmanr_feats = SelectKBest(self.get_spearmanr, k=self.select_n_feats).fit_transform(self.X[self.ordinal_feats], self.y)\n",
    "                # self.ordinal_kendalltau_feats = SelectKBest(self.get_kendalltau, k=self.select_n_feats).fit_transform(self.X[self.ordinal_feats], self.y)\n",
    "\n",
    "                self.selected_ordinal_feats = []\n",
    "                self.selected_ordinal_feats.extend(self.ordinal_spearmanr_feats)\n",
    "                self.selected_ordinal_feats.extend(self.ordinal_kendalltau_feats)\n",
    "                # self.selected_ordinal_feats = list(set(self.selected_ordinal_feats))\n",
    "\n",
    "        if self.nominal_feats is not None:\n",
    "\n",
    "            if self.is_target_cat:\n",
    "\n",
    "                self.nominal_mi_feats = self.get_kbest(X=self.X, feats_list=self.nominal_feats, metric=mutual_info_classif)\n",
    "                self.nominal_chi2_feats = self.get_kbest(X=self.X, feats_list=self.nominal_feats, metric=chi2)\n",
    "\n",
    "                self.selected_nominal_feats = []\n",
    "                self.selected_nominal_feats.extend(self.nominal_mi_feats)\n",
    "                self.selected_nominal_feats.extend(self.nominal_chi2_feats)\n",
    "\n",
    "            else:\n",
    "\n",
    "                self.f_feats = self.get_kbest(X=self.X, feats_list=self.nominal_feats, metric=f_classif, k=self.select_n_feats)\n",
    "                self.mi_feats = self.get_kbest(X=self.X, feats_list=self.nominal_feats, metric=mutual_info_regression, k=self.select_n_feats)\n",
    "\n",
    "                # # self.f_feats = f_classif(self.X[self.nominal_feats], self.y)[0]\n",
    "                # self.f_feats = SelectKBest(f_classif, k=self.select_n_feats).fit_transform(self.X[self.nominal_feats], self.y).columns\n",
    "                \n",
    "                # # self.mi_feats = mutual_info_regression(self.X[self.nominal_feats], self.y)\n",
    "                # self.mi_feats = SelectKBest(mutual_info_regression, k=self.select_n_feats).fit_transform(self.X[self.nominal_feats], self.y).columns\n",
    "\n",
    "                self.selected_nominal_feats = []\n",
    "                self.selected_nominal_feats.extend(self.f_feats)\n",
    "                self.selected_nominal_feats.extend(self.mi_feats)\n",
    "                # self.selected_nominal_feats = list(set(self.selected_nominal_feats))\n",
    "\n",
    "        if self.model is not None:\n",
    "            # np.int = np.int32\n",
    "            # np.float = np.float64\n",
    "            # np.bool = np.bool_\n",
    "            self.boruto_feats =  self.get_boruto_feats()\n",
    "            self.rfe_feats = self.get_rfe_feats()\n",
    "            \n",
    "\n",
    "        self.selected_num_feats.extend(self.boruto_feats)\n",
    "        self.selected_num_feats.extend(self.rfe_feats)\n",
    "        num_feats_dict = dict(Counter(self.selected_num_feats))\n",
    "        self.selected_num_feats = [i for i in num_feats_dict if num_feats_dict[i] >= 2]\n",
    "\n",
    "        self.selected_ordinal_feats.extend(self.boruto_feats)\n",
    "        self.selected_ordinal_feats.extend(self.rfe_feats)\n",
    "        ordinal_feats_dict = dict(Counter(self.selected_ordinal_feats))\n",
    "        self.selected_ordinal_feats = [i for i in ordinal_feats_dict if ordinal_feats_dict[i] >= 2]\n",
    "\n",
    "        self.selected_nominal_feats.extend(self.boruto_feats)\n",
    "        self.selected_nominal_feats.extend(self.rfe_feats)\n",
    "        nominal_feats_dict = dict(Counter(self.selected_nominal_feats))\n",
    "        self.selected_nominal_feats = [i for i in nominal_feats_dict if nominal_feats_dict[i] >= 2]\n",
    "\n",
    "        self.selected_feats = []\n",
    "        self.selected_feats.extend(self.selected_num_feats)\n",
    "        self.selected_feats.extend(self.selected_ordinal_feats)\n",
    "        self.selected_feats.extend(self.selected_nominal_feats)\n",
    "        self.selected_feats.extend(self.boruto_feats)\n",
    "        self.selected_feats = list(set(self.selected_feats))\n",
    "\n",
    "        return self.selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for idx in tqdm(range(1)):\n",
    "\n",
    "    X_train = train_df.iloc[skfold_list[idx][0]].reset_index(drop=True)\n",
    "    y_train = train_df.iloc[skfold_list[idx][0]]['loan_default'].to_frame().reset_index(drop=True)\n",
    "\n",
    "    X_valid = train_df.iloc[skfold_list[idx][1]].reset_index(drop=True)\n",
    "    y_valid = train_df.iloc[skfold_list[idx][1]]['loan_default'].to_frame().reset_index(drop=True)\n",
    "\n",
    "    for col in created_ratio_list:\n",
    "        if X_train[col].isnull().sum() != 0:\n",
    "            X_train[col].fillna(X_train[col].median(), inplace=True)\n",
    "        if X_valid[col].isnull().sum() != 0:\n",
    "            X_valid[col].fillna(X_train[col].median(), inplace=True)\n",
    "\n",
    "    # creating some extra features\n",
    "    temp_empl_type_map_dict = X_train.groupby('Employment.Type')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_empl_type_map_dict:\n",
    "        X_train[f\"empl_t_{i_keys[0]}_{i_keys[1]}\"] = X_train['Employment.Type'].map(temp_empl_type_map_dict[i_keys])\n",
    "        X_valid[f\"empl_t_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Employment.Type'].map(temp_empl_type_map_dict[i_keys])\n",
    "\n",
    "    temp_disb_month_map_dict = X_train.groupby('disb_month')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_disb_month_map_dict:\n",
    "        X_train[f\"dm_{i_keys[0]}_{i_keys[1]}\"] = X_train['disb_month'].map(temp_disb_month_map_dict[i_keys])\n",
    "        X_valid[f\"dm_{i_keys[0]}_{i_keys[1]}\"] = X_valid['disb_month'].map(temp_disb_month_map_dict[i_keys])\n",
    "\n",
    "    temp_score_desc_map_dict = X_train.groupby('score_desc')[\n",
    "        [\n",
    "            'ltv', 'PERFORM_CNS.SCORE', 'PRI.NO.OF.ACCTS', \n",
    "            'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE',\n",
    "            'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "            'age', 'hist_length', 'avg_loan_tenure'\n",
    "        ]\n",
    "    ].agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_score_desc_map_dict:\n",
    "        X_train[f\"sd_{i_keys[0]}_{i_keys[1]}\"] = X_train['score_desc'].map(temp_score_desc_map_dict[i_keys])\n",
    "        X_valid[f\"sd_{i_keys[0]}_{i_keys[1]}\"] = X_valid['score_desc'].map(temp_score_desc_map_dict[i_keys])\n",
    "\n",
    "    temp_aadhar_flag_map_dict = X_train.groupby('Aadhar_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_aadhar_flag_map_dict:\n",
    "        X_train[f\"af_{i_keys[0]}_{i_keys[1]}\"] = X_train['Aadhar_flag'].map(temp_aadhar_flag_map_dict[i_keys])\n",
    "        X_valid[f\"af_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Aadhar_flag'].map(temp_aadhar_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_pan_flag_map_dict = X_train.groupby('PAN_flag')[['ltv', 'PERFORM_CNS.SCORE']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_pan_flag_map_dict:\n",
    "        X_train[f\"pf_{i_keys[0]}_{i_keys[1]}\"] = X_train['PAN_flag'].map(temp_pan_flag_map_dict[i_keys])\n",
    "        X_valid[f\"pf_{i_keys[0]}_{i_keys[1]}\"] = X_valid['PAN_flag'].map(temp_pan_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_voterid_flag_map_dict = X_train.groupby('VoterID_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_voterid_flag_map_dict:\n",
    "        X_train[f\"vf_{i_keys[0]}_{i_keys[1]}\"] = X_train['VoterID_flag'].map(temp_voterid_flag_map_dict[i_keys])\n",
    "        X_valid[f\"vf_{i_keys[0]}_{i_keys[1]}\"] = X_valid['VoterID_flag'].map(temp_voterid_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_driving_flag_map_dict = X_train.groupby('Driving_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_driving_flag_map_dict:\n",
    "        X_train[f\"df_{i_keys[0]}_{i_keys[1]}\"] = X_train['Driving_flag'].map(temp_driving_flag_map_dict[i_keys])\n",
    "        X_valid[f\"df_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Driving_flag'].map(temp_driving_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_passport_flag_map_dict = X_train.groupby('Passport_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_passport_flag_map_dict:\n",
    "        X_train[f\"passf_{i_keys[0]}_{i_keys[1]}\"] = X_train['Passport_flag'].map(temp_passport_flag_map_dict[i_keys])\n",
    "        X_valid[f\"passf_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Passport_flag'].map(temp_passport_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_state_id_map_dict = X_train.groupby('State_ID')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_state_id_map_dict:\n",
    "        X_train[f\"si_{i_keys[0]}_{i_keys[1]}\"] = X_train['State_ID'].map(temp_state_id_map_dict[i_keys])\n",
    "        X_valid[f\"si_{i_keys[0]}_{i_keys[1]}\"] = X_valid['State_ID'].map(temp_state_id_map_dict[i_keys])\n",
    "\n",
    "    # getting categorical features\n",
    "    flag_columns = [col for col in X_train.columns if col.endswith('_flag') or col.endswith('_Flag')]\n",
    "\n",
    "    id_columns = [\n",
    "        'branch_id', 'supplier_id', 'manufacturer_id', \n",
    "        'Current_pincode_ID', 'State_ID', 'Employee_code_ID'\n",
    "    ]\n",
    "\n",
    "    categorical_features = list(X_train.select_dtypes(include=['object']).columns)\n",
    "    categorical_features.append('disb_month')\n",
    "    categorical_features.append('score_desc')\n",
    "    categorical_features.extend(flag_columns)\n",
    "    categorical_features.extend(id_columns)\n",
    "\n",
    "    # getting numerical features\n",
    "    numerical_features = list(X_train.select_dtypes(exclude=['object']).columns)\n",
    "    numerical_features.remove('loan_default')\n",
    "    numerical_features.remove('disb_month')\n",
    "    numerical_features.remove('score_desc')\n",
    "    numerical_features.remove('UniqueID')\n",
    "    for col in flag_columns:\n",
    "        numerical_features.remove(col)\n",
    "    for col in id_columns:\n",
    "        numerical_features.remove(col)\n",
    "\n",
    "    #getting all features\n",
    "    all_features = []\n",
    "    all_features.extend(categorical_features)\n",
    "    all_features.extend(numerical_features)\n",
    "\n",
    "    X_train = X_train[all_features]\n",
    "    X_valid = X_valid[all_features]\n",
    "\n",
    "    models_list = [RandomForestClassifier(), XGBClassifier()]\n",
    "    model_names_list = ['RandomForestClassifier', 'XGBClassifier']\n",
    "\n",
    "    ordinal_features = ['disb_month']\n",
    "    nominal_features = [col for col in categorical_features if col not in ordinal_features]\n",
    "\n",
    "    for model_idx in tqdm(range(len(model_names_list))):\n",
    "\n",
    "        model_name = model_names_list[model_idx]\n",
    "\n",
    "        results_dict[model_name] = {}\n",
    "\n",
    "        # feature selection\n",
    "        model = models_list[model_idx]\n",
    "\n",
    "        # feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=1, max_iter=30)\n",
    "        # feat_selector.fit(np.array(X_train), np.array(y_train))\n",
    "        # selected_features = list(X_train.iloc[:, feat_selector.support_].columns)\n",
    "\n",
    "        fselector = FSelector(\n",
    "            X=X_train, \n",
    "            y=y_train, \n",
    "            num_feats=numerical_features, \n",
    "            ordinal_feats=ordinal_features, \n",
    "            nominal_feats=nominal_features, \n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        selected_features = fselector.get_votes()\n",
    "\n",
    "        if len(selected_features) == 0:\n",
    "            continue\n",
    "\n",
    "        # model training\n",
    "        model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "        # metric calculation\n",
    "        y_train_pred = model.predict(X_train[selected_features])\n",
    "        y_train_pred_prob = model.predict_proba(X_train[selected_features])[:, 1]\n",
    "\n",
    "        y_valid_pred = model.predict(X_valid[selected_features])\n",
    "        y_valid_pred_prob = model.predict_proba(X_valid[selected_features])[:, 1]\n",
    "\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        train_roc_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "\n",
    "        valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        valid_f1 = f1_score(y_valid, y_valid_pred)\n",
    "        valid_roc_auc = roc_auc_score(y_valid, y_valid_pred_prob)\n",
    "\n",
    "        results_dict[model_name][idx+1] = {}\n",
    "        results_dict[model_name][idx+1]['selected_feats'] = selected_features\n",
    "        results_dict[model_name][idx+1]['train_acc'] = train_acc\n",
    "        results_dict[model_name][idx+1]['train_f1'] = train_f1\n",
    "        results_dict[model_name][idx+1]['train_roc_auc'] = train_roc_auc\n",
    "        results_dict[model_name][idx+1]['valid_acc'] = valid_acc\n",
    "        results_dict[model_name][idx+1]['valid_f1'] = valid_f1\n",
    "        results_dict[model_name][idx+1]['valid_roc_auc'] = valid_roc_auc\n",
    "        results_dict[model_name][idx+1]['model'] = model\n",
    "\n",
    "        print(f\"##### {model_name} #####\")\n",
    "        print(f\"Selected features: {selected_features}\")\n",
    "        print(\"Train:\")\n",
    "        print(f\"Accuracy: {train_acc:.5f}, F1: {train_f1:.5f}, ROC-AUC: {train_roc_auc:.5f}\")\n",
    "        print(\"Validation:\")\n",
    "        print(f\"Accuracy: {valid_acc:.5f}, F1: {valid_f1:.5f}, ROC-AUC: {valid_roc_auc:.5f}\")\n",
    "\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    del temp_empl_type_map_dict, temp_disb_month_map_dict, temp_score_desc_map_dict\n",
    "    del temp_aadhar_flag_map_dict, temp_pan_flag_map_dict, temp_voterid_flag_map_dict\n",
    "    del temp_driving_flag_map_dict, temp_passport_flag_map_dict, temp_state_id_map_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBClassifier': {1: {'selected_feats': ['Aadhar_flag',\n",
       "    'PRI.NO.OF.ACCTS_ratio10',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio19',\n",
       "    'hist_length_ratio18',\n",
       "    'sd_PRI.OVERDUE.ACCTS_mean',\n",
       "    'empl_t_ltv_get_iqr',\n",
       "    'NO.OF_INQUIRIES_ratio3',\n",
       "    'score_desc',\n",
       "    'dm_ltv_get_iqr',\n",
       "    'sd_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
       "    'manufacturer_id',\n",
       "    'PRI.OVERDUE.ACCTS_ratio1',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio4',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio1',\n",
       "    'PAN_flag',\n",
       "    'si_avg_loan_tenure_mean',\n",
       "    'State_ID',\n",
       "    'NO.OF_INQUIRIES_ratio4',\n",
       "    'PRI.OVERDUE.ACCTS_ratio6',\n",
       "    'PRI.NO.OF.ACCTS_ratio16',\n",
       "    'PRIMARY.INSTAL.AMT_ratio5',\n",
       "    'Employment.Type',\n",
       "    'disbursed_amount',\n",
       "    'NO.OF_INQUIRIES_ratio1',\n",
       "    'sd_PRI.NO.OF.ACCTS_get_iqr',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio13',\n",
       "    'ltv',\n",
       "    'NO.OF_INQUIRIES_ratio6',\n",
       "    'NO.OF_INQUIRIES_ratio19',\n",
       "    'hist_length_ratio3',\n",
       "    'dm_age_get_q25',\n",
       "    'VoterID_flag',\n",
       "    'branch_id',\n",
       "    'PRI.OVERDUE.ACCTS_ratio5',\n",
       "    'hist_length_ratio16',\n",
       "    'Passport_flag',\n",
       "    'NO.OF_INQUIRIES_ratio5',\n",
       "    'Driving_flag',\n",
       "    'PRI.DISBURSED.AMOUNT_ratio18',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio11',\n",
       "    'PRI.DISBURSED.AMOUNT_ratio3',\n",
       "    'PRI.CURRENT.BALANCE_ratio15',\n",
       "    'sd_PRI.OVERDUE.ACCTS_get_iqr',\n",
       "    'PERFORM_CNS.SCORE',\n",
       "    'PRI.OVERDUE.ACCTS_ratio19',\n",
       "    'PRI.SANCTIONED.AMOUNT_ratio6',\n",
       "    'zodiac_sign',\n",
       "    'dm_PERFORM_CNS.SCORE_get_q75',\n",
       "    'PRI.ACTIVE.ACCTS_ratio3',\n",
       "    'disb_month',\n",
       "    'PRI.NO.OF.ACCTS_ratio13',\n",
       "    'si_ltv_get_iqr',\n",
       "    'hist_length_ratio2',\n",
       "    'si_PERFORM_CNS.SCORE_mean',\n",
       "    'Current_pincode_ID',\n",
       "    'Employee_code_ID',\n",
       "    'hist_length_ratio15',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio6',\n",
       "    'supplier_id',\n",
       "    'NEW.ACCTS.IN.LAST.SIX.MONTHS_ratio17',\n",
       "    'dm_age_mean'],\n",
       "   'train_acc': 0.799917078889429,\n",
       "   'train_f1': 0.17781259179477138,\n",
       "   'train_roc_auc': 0.7677195341574667,\n",
       "   'valid_acc': 0.7805798593240693,\n",
       "   'valid_f1': 0.08348262271587245,\n",
       "   'valid_roc_auc': 0.6603981575423492,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                 colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                 enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                 gamma=None, grow_policy=None, importance_type=None,\n",
       "                 interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                 max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 multi_strategy=None, n_estimators=132, n_jobs=None,\n",
       "                 num_parallel_tree=None, random_state=1594458711, ...)}},\n",
       " 'LGBMClassifier': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBClassifier': {1: {'selected_feats': ['Aadhar_flag',\n",
       "    'PRI.NO.OF.ACCTS_ratio10',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio19',\n",
       "    'hist_length_ratio18',\n",
       "    'sd_PRI.OVERDUE.ACCTS_mean',\n",
       "    'empl_t_ltv_get_iqr',\n",
       "    'NO.OF_INQUIRIES_ratio3',\n",
       "    'score_desc',\n",
       "    'dm_ltv_get_iqr',\n",
       "    'sd_DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_mean',\n",
       "    'manufacturer_id',\n",
       "    'PRI.OVERDUE.ACCTS_ratio1',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio4',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio1',\n",
       "    'PAN_flag',\n",
       "    'si_avg_loan_tenure_mean',\n",
       "    'State_ID',\n",
       "    'NO.OF_INQUIRIES_ratio4',\n",
       "    'PRI.OVERDUE.ACCTS_ratio6',\n",
       "    'PRI.NO.OF.ACCTS_ratio16',\n",
       "    'PRIMARY.INSTAL.AMT_ratio5',\n",
       "    'Employment.Type',\n",
       "    'disbursed_amount',\n",
       "    'NO.OF_INQUIRIES_ratio1',\n",
       "    'sd_PRI.NO.OF.ACCTS_get_iqr',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio13',\n",
       "    'ltv',\n",
       "    'NO.OF_INQUIRIES_ratio6',\n",
       "    'NO.OF_INQUIRIES_ratio19',\n",
       "    'hist_length_ratio3',\n",
       "    'dm_age_get_q25',\n",
       "    'VoterID_flag',\n",
       "    'branch_id',\n",
       "    'PRI.OVERDUE.ACCTS_ratio5',\n",
       "    'hist_length_ratio16',\n",
       "    'Passport_flag',\n",
       "    'NO.OF_INQUIRIES_ratio5',\n",
       "    'Driving_flag',\n",
       "    'PRI.DISBURSED.AMOUNT_ratio18',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio11',\n",
       "    'PRI.DISBURSED.AMOUNT_ratio3',\n",
       "    'PRI.CURRENT.BALANCE_ratio15',\n",
       "    'sd_PRI.OVERDUE.ACCTS_get_iqr',\n",
       "    'PERFORM_CNS.SCORE',\n",
       "    'PRI.OVERDUE.ACCTS_ratio19',\n",
       "    'PRI.SANCTIONED.AMOUNT_ratio6',\n",
       "    'zodiac_sign',\n",
       "    'dm_PERFORM_CNS.SCORE_get_q75',\n",
       "    'PRI.ACTIVE.ACCTS_ratio3',\n",
       "    'disb_month',\n",
       "    'PRI.NO.OF.ACCTS_ratio13',\n",
       "    'si_ltv_get_iqr',\n",
       "    'hist_length_ratio2',\n",
       "    'si_PERFORM_CNS.SCORE_mean',\n",
       "    'Current_pincode_ID',\n",
       "    'Employee_code_ID',\n",
       "    'hist_length_ratio15',\n",
       "    'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS_ratio6',\n",
       "    'supplier_id',\n",
       "    'NEW.ACCTS.IN.LAST.SIX.MONTHS_ratio17',\n",
       "    'dm_age_mean'],\n",
       "   'train_acc': 0.799917078889429,\n",
       "   'train_f1': 0.17781259179477138,\n",
       "   'train_roc_auc': 0.7677195341574667,\n",
       "   'valid_acc': 0.7805798593240693,\n",
       "   'valid_f1': 0.08348262271587245,\n",
       "   'valid_roc_auc': 0.6603981575423492,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                 colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                 enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                 gamma=None, grow_policy=None, importance_type=None,\n",
       "                 interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                 max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 multi_strategy=None, n_estimators=132, n_jobs=None,\n",
       "                 num_parallel_tree=None, random_state=1732404475, ...)}},\n",
       " 'LGBMClassifier': {},\n",
       " 'RandomForestClassifier': {1: {'selected_feats': ['PERFORM_CNS.SCORE',\n",
       "    'Aadhar_flag',\n",
       "    'PAN_flag',\n",
       "    'State_ID',\n",
       "    'VoterID_flag',\n",
       "    'branch_id',\n",
       "    'disbursed_amount',\n",
       "    'score_desc',\n",
       "    'disb_month',\n",
       "    'manufacturer_id',\n",
       "    'Passport_flag',\n",
       "    'Current_pincode_ID',\n",
       "    'Driving_flag',\n",
       "    'Employee_code_ID',\n",
       "    'supplier_id',\n",
       "    'ltv'],\n",
       "   'train_acc': 0.9954726979860654,\n",
       "   'train_f1': 0.9894851020498517,\n",
       "   'train_roc_auc': 0.9999253027239895,\n",
       "   'valid_acc': 0.7718305026591182,\n",
       "   'valid_f1': 0.12326961107448912,\n",
       "   'valid_roc_auc': 0.5944025642570123}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': {1: {'selected_feats': ['PERFORM_CNS.SCORE',\n",
       "    'Aadhar_flag',\n",
       "    'PAN_flag',\n",
       "    'State_ID',\n",
       "    'VoterID_flag',\n",
       "    'branch_id',\n",
       "    'disbursed_amount',\n",
       "    'score_desc',\n",
       "    'disb_month',\n",
       "    'manufacturer_id',\n",
       "    'Passport_flag',\n",
       "    'Current_pincode_ID',\n",
       "    'Driving_flag',\n",
       "    'Employee_code_ID',\n",
       "    'supplier_id',\n",
       "    'ltv'],\n",
       "   'train_acc': 0.9954726979860654,\n",
       "   'train_f1': 0.9894851020498517,\n",
       "   'train_roc_auc': 0.9999253027239895,\n",
       "   'valid_acc': 0.7718305026591182,\n",
       "   'valid_f1': 0.12326961107448912,\n",
       "   'valid_roc_auc': 0.5944025642570123,\n",
       "   'model': RandomForestClassifier(n_estimators=28,\n",
       "                          random_state=RandomState(MT19937) at 0x1F9D49C2F40)}},\n",
       " 'XGBClassifier': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t615\n",
      "Iteration: \t9 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t4\n",
      "Rejected: \t615\n",
      "Iteration: \t10 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t4\n",
      "Rejected: \t615\n",
      "Iteration: \t11 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t4\n",
      "Rejected: \t615\n",
      "Iteration: \t12 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t13 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t14 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t15 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t16 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t17 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t18 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t19 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t20 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t21 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t22 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t23 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t24 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t25 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t26 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t27 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t28 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t29 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t30 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t0\n",
      "Rejected: \t617\n",
      "##### Fold1 #####\n",
      "Selected features: ['Current_pincode_ID', 'ltv']\n",
      "Train:\n",
      "Accuracy: 0.96630, F1: 0.91926, ROC-AUC: 0.99458\n",
      "Validation:\n",
      "Accuracy: 0.73053, F1: 0.19562, ROC-AUC: 0.55757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [9:26:41<85:00:16, 34001.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t5\n",
      "Rejected: \t616\n",
      "Iteration: \t9 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t10 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t11 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t12 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t13 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t14 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t15 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t16 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t17 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t18 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t19 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t20 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t21 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t22 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t23 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t24 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t25 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t26 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t27 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t28 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t29 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t30 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t0\n",
      "Rejected: \t617\n",
      "##### Fold2 #####\n",
      "Selected features: ['Current_pincode_ID', 'ltv']\n",
      "Train:\n",
      "Accuracy: 0.96593, F1: 0.91843, ROC-AUC: 0.99445\n",
      "Validation:\n",
      "Accuracy: 0.73383, F1: 0.19591, ROC-AUC: 0.54986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [13:19:46<49:23:37, 22227.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t5\n",
      "Rejected: \t616\n",
      "Iteration: \t9 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t10 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t11 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t12 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t13 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t14 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t15 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t16 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t17 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t18 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t19 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t20 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t21 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t22 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t23 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t24 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t25 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t26 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t27 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t28 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t29 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t30 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t0\n",
      "Rejected: \t617\n",
      "##### Fold3 #####\n",
      "Selected features: ['Current_pincode_ID', 'ltv']\n",
      "Train:\n",
      "Accuracy: 0.96593, F1: 0.91829, ROC-AUC: 0.99450\n",
      "Validation:\n",
      "Accuracy: 0.73302, F1: 0.19791, ROC-AUC: 0.56030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [15:25:30<30:10:55, 15522.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t5\n",
      "Rejected: \t616\n",
      "Iteration: \t9 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t10 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t11 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t12 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t13 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t14 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t15 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t16 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t17 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t18 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t19 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t20 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t21 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t22 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t23 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t24 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t25 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t26 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t27 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t28 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t29 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t30 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t0\n",
      "Rejected: \t617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [17:31:14<20:37:15, 12372.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Fold4 #####\n",
      "Selected features: ['Current_pincode_ID', 'ltv']\n",
      "Train:\n",
      "Accuracy: 0.96572, F1: 0.91775, ROC-AUC: 0.99446\n",
      "Validation:\n",
      "Accuracy: 0.73332, F1: 0.19809, ROC-AUC: 0.55800\n",
      "Iteration: \t1 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t621\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 30\n",
      "Confirmed: \t0\n",
      "Tentative: \t5\n",
      "Rejected: \t616\n",
      "Iteration: \t9 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t10 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t11 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t12 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t13 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t14 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t15 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t16 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t17 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t18 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t19 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t20 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t21 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t3\n",
      "Rejected: \t616\n",
      "Iteration: \t22 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t23 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t24 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t25 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t26 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t27 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t28 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "Iteration: \t29 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t617\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t30 / 30\n",
      "Confirmed: \t2\n",
      "Tentative: \t0\n",
      "Rejected: \t617\n",
      "##### Fold5 #####\n",
      "Selected features: ['Current_pincode_ID', 'ltv']\n",
      "Train:\n",
      "Accuracy: 0.96583, F1: 0.91801, ROC-AUC: 0.99448\n",
      "Validation:\n",
      "Accuracy: 0.73373, F1: 0.19439, ROC-AUC: 0.55211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [20:47:47<20:47:47, 14973.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m    126\u001b[0m feat_selector \u001b[38;5;241m=\u001b[39m BorutaPy(model, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m--> 127\u001b[0m \u001b[43mfeat_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(X_train\u001b[38;5;241m.\u001b[39miloc[:, feat_selector\u001b[38;5;241m.\u001b[39msupport_]\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(selected_features) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\boruta\\boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m        The target values.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\boruta\\boruta_py.py:285\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mset_params(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# add shadow attributes, shuffle them and train estimator, get imps\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m cur_imp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_shadows_get_imps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_reg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# get the threshold of shadow importances we will use for rejection\u001b[39;00m\n\u001b[0;32m    288\u001b[0m imp_sha_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(cur_imp[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperc)\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\boruta\\boruta_py.py:412\u001b[0m, in \u001b[0;36mBorutaPy._add_shadows_get_imps\u001b[1;34m(self, X, y, dec_reg)\u001b[0m\n\u001b[0;32m    410\u001b[0m x_sha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shuffle, \u001b[38;5;241m0\u001b[39m, x_sha)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# get importance of the merged matrix\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m imp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_imp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# separate importances of real and shadow features\u001b[39;00m\n\u001b[0;32m    414\u001b[0m imp_sha \u001b[38;5;241m=\u001b[39m imp[x_cur_w:]\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\boruta\\boruta_py.py:384\u001b[0m, in \u001b[0;36mBorutaPy._get_imp\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_imp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease check your X and y variable. The provided\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    387\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator cannot be fitted to your data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "results_dict['RandomForest'] = {}\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(skfold_list))):\n",
    "\n",
    "    X_train = train_df.iloc[skfold_list[idx][0]].reset_index(drop=True)\n",
    "    y_train = train_df.iloc[skfold_list[idx][0]]['loan_default'].to_frame().reset_index(drop=True)\n",
    "\n",
    "    X_valid = train_df.iloc[skfold_list[idx][1]].reset_index(drop=True)\n",
    "    y_valid = train_df.iloc[skfold_list[idx][1]]['loan_default'].to_frame().reset_index(drop=True)\n",
    "\n",
    "    for col in created_ratio_list:\n",
    "        if X_train[col].isnull().sum() != 0:\n",
    "            X_train[col].fillna(X_train[col].median(), inplace=True)\n",
    "        if X_valid[col].isnull().sum() != 0:\n",
    "            X_valid[col].fillna(X_train[col].median(), inplace=True)\n",
    "\n",
    "    # creating some extra features\n",
    "    temp_empl_type_map_dict = X_train.groupby('Employment.Type')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_empl_type_map_dict:\n",
    "        X_train[f\"empl_t_{i_keys[0]}_{i_keys[1]}\"] = X_train['Employment.Type'].map(temp_empl_type_map_dict[i_keys])\n",
    "        X_valid[f\"empl_t_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Employment.Type'].map(temp_empl_type_map_dict[i_keys])\n",
    "\n",
    "    temp_disb_month_map_dict = X_train.groupby('disb_month')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_disb_month_map_dict:\n",
    "        X_train[f\"dm_{i_keys[0]}_{i_keys[1]}\"] = X_train['disb_month'].map(temp_disb_month_map_dict[i_keys])\n",
    "        X_valid[f\"dm_{i_keys[0]}_{i_keys[1]}\"] = X_valid['disb_month'].map(temp_disb_month_map_dict[i_keys])\n",
    "\n",
    "    temp_score_desc_map_dict = X_train.groupby('score_desc')[\n",
    "        [\n",
    "            'ltv', 'PERFORM_CNS.SCORE', 'PRI.NO.OF.ACCTS', \n",
    "            'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE',\n",
    "            'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "            'age', 'hist_length', 'avg_loan_tenure'\n",
    "        ]\n",
    "    ].agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_score_desc_map_dict:\n",
    "        X_train[f\"sd_{i_keys[0]}_{i_keys[1]}\"] = X_train['score_desc'].map(temp_score_desc_map_dict[i_keys])\n",
    "        X_valid[f\"sd_{i_keys[0]}_{i_keys[1]}\"] = X_valid['score_desc'].map(temp_score_desc_map_dict[i_keys])\n",
    "\n",
    "    temp_aadhar_flag_map_dict = X_train.groupby('Aadhar_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_aadhar_flag_map_dict:\n",
    "        X_train[f\"af_{i_keys[0]}_{i_keys[1]}\"] = X_train['Aadhar_flag'].map(temp_aadhar_flag_map_dict[i_keys])\n",
    "        X_valid[f\"af_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Aadhar_flag'].map(temp_aadhar_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_pan_flag_map_dict = X_train.groupby('PAN_flag')[['ltv', 'PERFORM_CNS.SCORE']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_pan_flag_map_dict:\n",
    "        X_train[f\"pf_{i_keys[0]}_{i_keys[1]}\"] = X_train['PAN_flag'].map(temp_pan_flag_map_dict[i_keys])\n",
    "        X_valid[f\"pf_{i_keys[0]}_{i_keys[1]}\"] = X_valid['PAN_flag'].map(temp_pan_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_voterid_flag_map_dict = X_train.groupby('VoterID_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_voterid_flag_map_dict:\n",
    "        X_train[f\"vf_{i_keys[0]}_{i_keys[1]}\"] = X_train['VoterID_flag'].map(temp_voterid_flag_map_dict[i_keys])\n",
    "        X_valid[f\"vf_{i_keys[0]}_{i_keys[1]}\"] = X_valid['VoterID_flag'].map(temp_voterid_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_driving_flag_map_dict = X_train.groupby('Driving_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_driving_flag_map_dict:\n",
    "        X_train[f\"df_{i_keys[0]}_{i_keys[1]}\"] = X_train['Driving_flag'].map(temp_driving_flag_map_dict[i_keys])\n",
    "        X_valid[f\"df_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Driving_flag'].map(temp_driving_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_passport_flag_map_dict = X_train.groupby('Passport_flag')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_passport_flag_map_dict:\n",
    "        X_train[f\"passf_{i_keys[0]}_{i_keys[1]}\"] = X_train['Passport_flag'].map(temp_passport_flag_map_dict[i_keys])\n",
    "        X_valid[f\"passf_{i_keys[0]}_{i_keys[1]}\"] = X_valid['Passport_flag'].map(temp_passport_flag_map_dict[i_keys])\n",
    "\n",
    "    temp_state_id_map_dict = X_train.groupby('State_ID')[['ltv', 'PERFORM_CNS.SCORE', 'age', 'hist_length', 'avg_loan_tenure']].\\\n",
    "        agg([np.median, np.mean, get_q25, get_q75, get_iqr]).to_dict()\n",
    "\n",
    "    for i_keys in temp_state_id_map_dict:\n",
    "        X_train[f\"si_{i_keys[0]}_{i_keys[1]}\"] = X_train['State_ID'].map(temp_state_id_map_dict[i_keys])\n",
    "        X_valid[f\"si_{i_keys[0]}_{i_keys[1]}\"] = X_valid['State_ID'].map(temp_state_id_map_dict[i_keys])\n",
    "\n",
    "    # getting categorical features\n",
    "    flag_columns = [col for col in X_train.columns if col.endswith('_flag') or col.endswith('_Flag')]\n",
    "\n",
    "    id_columns = [\n",
    "        'branch_id', 'supplier_id', 'manufacturer_id', \n",
    "        'Current_pincode_ID', 'State_ID', 'Employee_code_ID'\n",
    "    ]\n",
    "\n",
    "    categorical_features = list(X_train.select_dtypes(include=['object']).columns)\n",
    "    categorical_features.append('disb_month')\n",
    "    categorical_features.append('score_desc')\n",
    "    categorical_features.extend(flag_columns)\n",
    "    categorical_features.extend(id_columns)\n",
    "\n",
    "    # getting numerical features\n",
    "    numerical_features = list(X_train.select_dtypes(exclude=['object']).columns)\n",
    "    numerical_features.remove('loan_default')\n",
    "    numerical_features.remove('disb_month')\n",
    "    numerical_features.remove('score_desc')\n",
    "    numerical_features.remove('UniqueID')\n",
    "    for col in flag_columns:\n",
    "        numerical_features.remove(col)\n",
    "    for col in id_columns:\n",
    "        numerical_features.remove(col)\n",
    "\n",
    "    #getting all features\n",
    "    all_features = []\n",
    "    all_features.extend(categorical_features)\n",
    "    all_features.extend(numerical_features)\n",
    "\n",
    "    X_train = X_train[all_features]\n",
    "    X_valid = X_valid[all_features]\n",
    "\n",
    "    # feature selection\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=1, max_iter=30)\n",
    "    feat_selector.fit(np.array(X_train), np.array(y_train))\n",
    "    selected_features = list(X_train.iloc[:, feat_selector.support_].columns)\n",
    "\n",
    "    if len(selected_features) == 0:\n",
    "        continue\n",
    "\n",
    "    # model training\n",
    "    model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "    # metric calculation\n",
    "    y_train_pred = model.predict(X_train[selected_features])\n",
    "    y_train_pred_prob = model.predict_proba(X_train[selected_features])[:, 1]\n",
    "\n",
    "    y_valid_pred = model.predict(X_valid[selected_features])\n",
    "    y_valid_pred_prob = model.predict_proba(X_valid[selected_features])[:, 1]\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "\n",
    "    valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    valid_f1 = f1_score(y_valid, y_valid_pred)\n",
    "    valid_roc_auc = roc_auc_score(y_valid, y_valid_pred_prob)\n",
    "\n",
    "    results_dict['RandomForest'][idx+1] = {}\n",
    "    results_dict['RandomForest'][idx+1]['selected_feats'] = selected_features\n",
    "    results_dict['RandomForest'][idx+1]['train_acc'] = train_acc\n",
    "    results_dict['RandomForest'][idx+1]['train_f1'] = train_f1\n",
    "    results_dict['RandomForest'][idx+1]['train_roc_auc'] = train_roc_auc\n",
    "    results_dict['RandomForest'][idx+1]['valid_acc'] = valid_acc\n",
    "    results_dict['RandomForest'][idx+1]['valid_f1'] = valid_f1\n",
    "    results_dict['RandomForest'][idx+1]['valid_roc_auc'] = valid_roc_auc\n",
    "    results_dict['RandomForest'][idx+1]['model'] = model\n",
    "\n",
    "    print(f\"##### Fold{idx+1} #####\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    print(\"Train:\")\n",
    "    print(f\"Accuracy: {train_acc:.5f}, F1: {train_f1:.5f}, ROC-AUC: {train_roc_auc:.5f}\")\n",
    "    print(\"Validation:\")\n",
    "    print(f\"Accuracy: {valid_acc:.5f}, F1: {valid_f1:.5f}, ROC-AUC: {valid_roc_auc:.5f}\")\n",
    "\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    del temp_empl_type_map_dict, temp_disb_month_map_dict, temp_score_desc_map_dict\n",
    "    del temp_aadhar_flag_map_dict, temp_pan_flag_map_dict, temp_voterid_flag_map_dict\n",
    "    del temp_driving_flag_map_dict, temp_passport_flag_map_dict, temp_state_id_map_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Current_pincode_ID', 'ltv'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in results_dict['RandomForest']:\n",
    "    print(f\"##### Fold{idx} #####\")\n",
    "    print(f\"Selected features: {results_dict['RandomForest'][idx]['selected_features']}\")\n",
    "    print(\"Train:\")\n",
    "    print(f\"Accuracy: {results_dict['RandomForest'][idx]['train_acc']}\")\n",
    "    print(f\"F1: {results_dict['RandomForest'][idx]['train_f1']}\")\n",
    "    print(f\"ROC-AUC: {results_dict['RandomForest'][idx]['train_roc_auc']}\")\n",
    "    print(\"Validation:\")\n",
    "    print(f\"Accuracy: {results_dict['RandomForest'][idx]['valid_acc']}\")\n",
    "    print(f\"F1: {results_dict['RandomForest'][idx]['valid_f1']}\")\n",
    "    print(f\"ROC-AUC: {results_dict['RandomForest'][idx]['valid_roc_auc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = [results_dict['RandomForest'][i]['train_acc'] for i in results_dict['RandomForest']]\n",
    "train_f1_list = [results_dict['RandomForest'][i]['train_f1'] for i in results_dict['RandomForest']]\n",
    "train_roc_auc_list = [results_dict['RandomForest'][i]['train_roc_auc'] for i in results_dict['RandomForest']]\n",
    "\n",
    "valid_acc_list = [results_dict['RandomForest'][i]['valid_acc'] for i in results_dict['RandomForest']]\n",
    "valid_f1_list = [results_dict['RandomForest'][i]['valid_f1'] for i in results_dict['RandomForest']]\n",
    "valid_roc_auc_list = [results_dict['RandomForest'][i]['valid_roc_auc'] for i in results_dict['RandomForest']]\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df['fold'] = [i for i in results_dict['RandomForest']]\n",
    "results_df['train_acc'] = train_acc_list\n",
    "results_df['train_f1'] = train_f1_list\n",
    "results_df['train_roc_auc'] = train_roc_auc_list\n",
    "results_df['valid_acc'] = valid_acc_list\n",
    "results_df['valid_f1'] = valid_f1_list\n",
    "results_df['valid_roc_auc'] = valid_roc_auc_list\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Aadhar_flag'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[skfold_list[0][0]].reset_index(drop=True)\n",
    "\n",
    "for col in created_ratio_list:\n",
    "    if X_train[col].median() != 0:\n",
    "        print(f\"{col}: {X_train[col].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in created_ratio_list:\n",
    "    if X_train[col].isnull().sum() != 0:\n",
    "        X_train[col].fillna(X_train[col].median(), inplace=True)\n",
    "        print(f\"{col}: {X_train[col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
